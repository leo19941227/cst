expdir: ???
num_workers: 8

trainer:
  max_epochs: 100
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  precision: 16
  log_every_n_steps: 100
save_steps: 1000
valid_metric: valid/wer
valid_higher_better: false

target: cst.models.asr.CtcASR

model:
  upstream_name: hubert
  downstream_conf:
    total_rate: 320
    module: 'LSTM'                        # 'LSTM'/'GRU'
    bidirection: True
    dim: [1024]
    dropout: [0.2]
    layer_norm: [False]
    proj: [True, True]              # Linear projection + Tanh after each rnn layer
    sample_rate: [1, 1]
    sample_style: 'drop'                  # 'drop'/'concat'
  lr: 1.0e-4

data:
  train_conf:
    data_list: data/asr/librispeech/train_clean_100
    total_samples: 10000000
    shuffle: true 
    num_workers: ${num_workers}
  valid_conf:
    data_list: data/asr/librispeech/test_clean
    total_samples: ${data.train_conf.total_samples}
    shuffle: false
    num_workers: ${num_workers}
